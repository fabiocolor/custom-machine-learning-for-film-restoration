Ok, for the final and optional step, we are going to do a MatchGrade. So a MatchGrade is kind of a node that Nuke uses to match the color information from a source and a reference. So this is useful for creating LUTs or similar color transformations. So you can do... basically it can work in three modes, I remember. It works as a 3D LUT, or as a... what is it called? A CDL. So basically like a monostatic transformation. Obviously the LUT is going to give you a better result. Same thing, for the MatchGrade we need only to match the number of frames that we are going to be using. Can we use... We can do two modes here. We can use MatchGradeSource or MatchDifferentClip. Sometimes MatchGradeSource may give us a good enough result, but sometimes it may introduce some artifacts. In that case we can use MatchDifferentClip. When you use MatchDifferentClip, the amount of artifacts are reduced, but the problem is that sometimes the accuracy of the matching is not going to be as good. So it's going to be something you need to play with. The number of reference frames are going to be the number of frames that you are using for training. In this case mostly 4, could be 8, could be 7, depending on the numbers that you set up in the dataset curation. Transformation is going to be a 3D LUT. The pre-LUT is going to be logarithmic, because before any of the target or the source dataset are going into the MatchGrade, we are going to do the same thing. We are going to do a linear to log conversion. This linear to log conversion will allow us to avoid any issues with values that are way above what we need for them to be. Once we finish the MatchGrade operation, then we do a Log2Linear to try to recover the original colors. In most cases this is going to work fine. So the pre-LUT transformation is going to be logarithmic. The LUT resolution is going to be 264, that's the maximum available that we have in the non-conversion operation. We cannot export LUTs here, so since we cannot export LUTs, we can only copy the MatchGrade and use it in another structure. So you can use your four frames to do the matching and then copy that MatchGrade node and paste it in another tree that is just going to copy those values to the whole reel or to the whole shot. So basically what we do is take the source dataset, it's going to be the whole reel, we do a linear to log conversion, we use the MatchGrade to set up that, then we do a Log2Linear conversion to get it back to linear, then we do a crop because we want to maximize the amount of image available for us to do the rendering. So we do a crop, we eliminate all of the sides, we are only left with the image, then we do a reformat to 1080p, then we export in EXAS HS2065. So in this case, this step is only because we want to achieve what is called like a comparison between the machine learning mode and the LUT mode. So for us to have, obviously, the problem with a LUT, I think it's kind of obvious that a LUT is a multiplication, so it's going to find the values that you have on the source, and it's going to multiply them by the LUT, and you're going to get a result. So the problem is that if the values don't exist on the source anymore, or they are too faded to properly exist on the source anymore, then any kind of multiplication is not going to be able to recover anything, so it's basically multiplying by zero. It's not really zero, but it's kind of multiplying by zero because it's not there anymore. So a LUT is always going to be an incomplete version of the color procedure, but the problem is that for a long time, people have thought that a LUT will give you a good enough result. So that is something that I want to also make a point about, because LUTs can only do what the source let them do. So in this case, by training our custom models, we can achieve this kind of stuff. So this is my main point about why I'm doing this comparison, because I need to do it because a lot of people will think, especially people that are working in VFX, oh, yes, I can do that with a LUT, or maybe you can do it with just using the color knobs in DaVinci Resolve, or using, I don't know, Faded Balance in the plugin that I made. Not really, because that color information is not there anymore.