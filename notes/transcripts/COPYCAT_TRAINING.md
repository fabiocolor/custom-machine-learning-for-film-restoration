OK, now for the third part, we're going to do the actual copycat training. So we have two postage stamps. One for the reference is going to be the target data set that's going to be aligned. The other postage stamp is going to be the source data set. So for the target data set, most of the time when we are using a video reference, or a television reference, or some sort of reference, it may come with a lot of dust, dirt, compression, a lot of elements that may introduce artifacts to the image. So what I usually do is to do some sort of filtering. That's why I use a median. So a median filter, I think, is the best way to filter this kind of stuff. Because the blur, unless you're using a really specific kind of blur, doesn't really achieve what I want to do here. So we do a median. Now the median, I'm doing the size 10. But it really depends on the quality of the reference. Sometimes the reference may need a lot less. But sometimes you may need a lot more. But in this case, 10, I think, was a good enough solution for this particular case. So it's something that you need to be aware of. And this highly depends on the quality of the reference. Sometimes you may only need to do one or two points, maybe three or four points. So that's something to take in consideration. For the postage stamp of the source data set, we're going to apply the same crop, the same linked crop or the same clone crop that we used in the alignment phase is going to be applied here. And then to both paths, we're going to use a color space. That color space is going to allow us. Because right now, we're working in RGB. So instead of working in RGB, we need to change to YUV. Why? Because we need to separate chroma from luma. So we're going to do a color space transform for both paths. And it's going to be linear to YUV. So we're going from a linear workflow to YCVCR or YUV. Then once we are in YUV, we're going to do a shuffle node. That shuffle node is going to do something really specific. It's going to take, since remember, we are not working in RGB anymore. We are working in YUV. So in YUV, red becomes luma. Green becomes U or CV. And blue becomes CR or B. And since we want the moment in the reference, in the reference, we only want the chroma information. We don't want the luma information because the luma information, since this is a video or a telecine or whatever, is usually really low. And we don't want to mess with that. So what we're going to do is extract the luma from the source and put it with the chroma of the reference. So basically, we are only keeping the CV and the CR of the reference, but using the luma of the source to kind of create this new version, this ground truth that we want to achieve. So once we do that, and once we have extracted the luma out of the source, we go back to RGB. So we do another color space transform that goes from YCVCR to linear. Then basically, at this point, we are kind of ready. Our ground truth and our source should be exactly the same. But we need to do some cleanup, especially to avoid any type of artifacts. So we're going to do a grade node. This grade node, exactly what is the only thing that this grade node is doing is a black clamp and a white clamp to avoid any type of sub-0 values or above 1 values. So basically, we're doing a black clamp and a white clamp. Then we are going to do a remove channel operation. And in this remove channel operation, we are removing the alpha channel. Since we only want to train RGB, and to be honest, CopyCat works better when you only train the RGB channels, then we need to remove the extra channel that's going to be the alpha channel. So we do the same for both. And to avoid any kind of issue with the bounding box, then we set up to copy the bounding box from the reference to the source. And it's kind of a quality control step as well. Then out of this result, then we can have a true ground truth and a true input. So at this point, the only difference, since we have extracted the luma from the source and used the chroma from the reference, the only difference between the ground truth and the input should be color. Everything else should be exactly the same. They should have the same information, the same resolution. Everything else should be exactly the same. The only difference is that one should have the original colors of the reference, on the other hand, should have the source colors that are faded. So once we have that, then we are ready to do the training. So for the actual training, I have some specific settings that I used in the past that work really well for me, especially when I'm doing this shot by shot. So obviously, we need to use a GPU. In the case of Mac, you can only do Apple Silicon. Well, to a degree, you can use some of the old Navi cards. 
