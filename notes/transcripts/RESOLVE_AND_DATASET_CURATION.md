So in this recording we're going to be exploring my chroma recovery workflow, my chroma recovery workflow in Nuke. So the first step is going to be the dataset curation. In here we're going to ingest the results of our previous alignment that we did on Resolve. And basically what you're doing, what we're doing in Resolve is quite easy. We put the source, meaning the 4k or like the highest quality image available that we want to recover the color, and the reference that is going to be the ground truth that we're going to use to recover the color from. And then we're going to align them so they even, we are going to make them the same resolution and same frame rate so the frames are aligned. We need to do that because a lot of the times, especially for references, is if they are like video sources or something like that, they may have a different frame rate or and obviously they have like a different frame size. So we need to align for that. So even if the references, even if the reference now has like black borders on the sides and on top, we need to adjust so it matches as much as possible the source. So that's the first step. Then we render our work file that is going to be the data set that we're going to use. So we render, let's say, we render an EXR sequence from the reference and an EXR sequence from the source and we're going to use that for the data set curation. So in the data set curation, we can do it two ways. First, we're going to try to do the whole reel or the whole, usually the whole reel in a single thing, in a single project. Sometimes, to be honest, most of the time that's not going to work, but you can try. And then the other thing that we can do that is going to assure us to have a way better quality is to divide the reel by shots. And we're going to create a shot, we're going to create a project per shot. So it's akin to a VFX workflow. It's basically a VFX workflow. Obviously, it's going to take more time because you're going to have to create X number of VFX shots in comparison to one single reel, but obviously you're going to get way better quality. So then we fit each source or reference to a frame range. In that frame range, we're going to limit that to 1.1 in order to only pass one frame at a time. This is going to be useful because when we are doing the append a clip, we want only one frame to come at a time. So it is important we do the frame range first, and then we're going to do frame holds. So the number of frames that is going to get used by the dataset highly depends on the result. By default, I always like to use three. One in the beginning, one in the middle, one at the end. But lately, I found out that having four gives you a better head start. So one in the beginning, one at the end, and two in the middle. And let's say, so it's kind of simple. Let's say your shot goes from frame 20 to frame 60. So we got frame one is going to be frame 20, the last frame is going to be frame 60, and then in the middle, we're going to have like maybe 30 and 50, or it will be like 20 plus 60 divided by 4, it's 80, 20, 20, 20. So it will be like 20, 40, 60. Or no, in this case, it will be yeah, 20, 40. Or 20, 40, 40, because it's 40, 60. But you get the idea. It has to be like a divided number that will give us a good division between the frames. And all those frame holds will go to an append clip. And from that append clip, it's going to have x number of frames that we're going to be using. And then it goes to add. So the reason that there are two append clips is because the second append clip, the one on the bottom, is the one connected to a lot of the postage stamps that we have through the node graph. So it's better if we're going to make like copies or deleting something to have a previous append clip. This is not going to affect anything to have like a second append clip. It's better for us to have it in order. Well, you could technically delete this, the first append clip, and only use the second. Yes, but it's going to make things harder when you want to like switch and switch between shots and like. So the numbers, the frame numbers that we have from the frame holds are basically shot-based or workflow-based or real-based. So we shouldn't guide each other for the numbers. The only thing is that we need to have one frame at the beginning, one frame at the end, and x number of frames in the middle. That's basically it. Then we're going to compare each of the frames that we have picked. So we need to do like a curation of the data set. So we're going to pick the first frame from the reference and the first frame from them, from the source, and we're going to compare if they are the same. If they have the same information, then that data set is okay. We're going to do the same thing for the second frame hold and so on and so forth. We have to check each individual frame to see if they contain the same information. Not color information, but just a luminal information. The same image, if they have the same image on the same frame number. And we need to check that between the source and the reference because everything depends on this. So this is the baseline of everything that we're going to do. So we need to make sure that both of them have the same information. And obviously, if the copycat training doesn't work, we can increase the size of the frame. We can increase the number of frame holds in the middle, usually. Like instead of doing four frames, we can do seven frames. And then we can go to 11 and so on and so forth, trying to add one frame in the middle of any... One frame in the middle of two frames. So we can have a better data set representation. But that's workflow dependent. But the number of... The idea is for us to have a minimum of three or four frame holds that we're going to use for the data set creation.
